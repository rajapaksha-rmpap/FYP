{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Applying DRL for FIR Filter Implementation - Stage 1 - Section 3.3** \n",
    "\n",
    "## Scope - *Training a Custom DDPG Agent With More Audio Data*\n",
    "References:- the book, *Deep Reinforcement Learning for Wireless Communications and Networking*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, copy\n",
    "import json\n",
    "import wave\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io import wavfile\n",
    "from scipy.fft import fft, rfft, fftshift, fftfreq\n",
    "from scipy.signal import convolve, freqz\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import A2C, DDPG, HER, PPO, SAC, TD3\n",
    "from stable_baselines3.common.base_class import BaseAlgorithm, VecEnv\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "sys.path.append('../')\n",
    "from helper import to_min_size_int_array, Spectrum, LPF, apply_filter, mean_L1_dist, SNR, create_target_and_jammed_signals, trim_audio\n",
    "from DDPG import DDPGAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **The Custom Environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReceiverEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    A custom environment developed in the accordance with gym environment API that immitates a receiver environment. \n",
    "    :param N: FIR filter length, must be an odd integer \n",
    "    :param S: signal partition size which will be used to calculate the receiver buffer size\n",
    "    :param cut_off_freq: the frequency to truncate the audio spectrum to generate the target signal; equivalent to the ideal cut-off frequency of the learned filter\n",
    "    :param interference_center_freq: the frequency to shift the target spectrum to generate the non-overlapping interference\n",
    "    :param audio_json: path of a json file containing the names of the audio wav files the environment can access\\\n",
    "        put the audio file names without the .wav extension in a json array inside the file\n",
    "    \"\"\"\n",
    "\n",
    "    # define constants \n",
    "    MIN_BUFFER_SIZE = 10 # RAISE THIS LATER!!!\n",
    "    EPISODE_LENGTH  = np.inf # np.inf\n",
    "    MAX_TOTAL_NUM_OF_STEPS = np.inf\n",
    "\n",
    "    def __init__(self, N:int, S:int, cut_off_freq:int, interference_center_freq:int, audio_num:int, audio_json:str = 'audio_files/audio_files.json'):\n",
    "\n",
    "        super(ReceiverEnv, self).__init__()\n",
    "\n",
    "        # ----- verifying input arguments and setting them as class atributes ----\n",
    "        # filter length \n",
    "        if N%2 != 1:\n",
    "            raise Exception(f\"FIR filter length 'N' must be an odd integer: given {N}\")\n",
    "        self.N = N\n",
    "\n",
    "        # signal partition size\n",
    "        if S < self.MIN_BUFFER_SIZE:\n",
    "            raise Exception(f\"the buffer size 'S' must be larger than MIN_BUFFER_SIZE, {self.MIN_BUFFER_SIZE}: given {S}\")\n",
    "        self.S = S\n",
    "        # buffer size \n",
    "        self.buffer_size = S + N - 1\n",
    "\n",
    "        # other parameters\n",
    "        self.cut_off_freq = cut_off_freq\n",
    "        self.interference_center_freq = interference_center_freq\n",
    "        self.audio_num = audio_num\n",
    "        self.audio_json = audio_json\n",
    "\n",
    "        # ----------------------------- Action Space -----------------------------\n",
    "        # action - choosing the filter coefficients [from index 0 to (N-1)/2]; \n",
    "        # note that the action is NOT TUNING/ADJUSTING/CHANGING the coefficeints of an existing filter that the agent is not aware of. \n",
    "        action_shape = (int((N+1)/2), )\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=action_shape, dtype=np.float32) # float16 -> float32\n",
    "\n",
    "        # ----------------------------- State Space ------------------------------\n",
    "        state_shape = (self.buffer_size, )\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=state_shape, dtype=np.int32)\n",
    "\n",
    "        # ------------------------- other class attributes ------------------------\n",
    "        self.global_counter = 0  # a counter to keep track of the number of elapsed time steps of the environment\n",
    "        self.counter = 0         # a counter to keep track of the number of elapsed time steps in the current episode\n",
    "        self.episode_counter = 0 # a counter to keep track of the number of total episodes\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "\n",
    "        super().reset(seed=seed, options=None) # options must be forced to None\n",
    "\n",
    "        # reset the counters\n",
    "        if options == 'reset_all':\n",
    "            self.global_counter  = 0\n",
    "            self.episode_counter = 0\n",
    "        self.counter = 0\n",
    "        self.episode_counter += 1\n",
    "\n",
    "        print('\\n' + \"-\" * 50 + f\"episode no: {self.episode_counter}\" + \"-\" * 50)\n",
    "\n",
    "        # for each episode, choose an audio signal randomly\n",
    "        with open(self.audio_json) as audio_json_file:\n",
    "            train_audio_names = json.load(audio_json_file)[\"train\"]\n",
    "        \n",
    "        i = np.random.randint(low=1, high=self.audio_num) # len(train_audio_names)\n",
    "        # create the target and jammed signals\n",
    "        target_signal, jammed_signal = create_target_and_jammed_signals(train_audio_names[i], self.cut_off_freq, self.interference_center_freq, self.S)\n",
    "        self.target_signal = target_signal\n",
    "        self.jammed_signal = jammed_signal\n",
    "\n",
    "        # return the initial state \n",
    "        self.state = jammed_signal[:self.buffer_size]\n",
    "\n",
    "        info = {}\n",
    "\n",
    "        # return the initial state and info\n",
    "        return self.state, info\n",
    "\n",
    "    def step(self, action):\n",
    "\n",
    "        # increment the counters\n",
    "        self.global_counter += 1\n",
    "        self.counter += 1\n",
    "\n",
    "        # create the filter \n",
    "        filter = np.concatenate((action[-1:0:-1], action))\n",
    "\n",
    "        # get signal partition from the buffer\n",
    "        partition = self.state\n",
    "        # print(f\"step: {self.counter}, state: {partition}\")\n",
    "\n",
    "        # generating the next state\n",
    "        terminated = False\n",
    "        if (self.S * self.counter) + self.buffer_size >= len(self.jammed_signal):\n",
    "            terminated = True\n",
    "        else:\n",
    "            self.state = self.jammed_signal[(self.S * self.counter) : (self.S * self.counter) + self.buffer_size]\n",
    "\n",
    "        # apply the filter to the current state (not on the next state)\n",
    "        filtered = apply_filter(filter, partition)[(self.N-1)//2 : (self.N-1)//2 + self.S]\n",
    "        target   = self.target_signal[(self.N-1)//2 + self.S * (self.counter - 1) : (self.N-1)//2 + self.S * (self.counter - 1) + self.S]\n",
    "        # print(f\"filtered: {filtered}\")\n",
    "        # print(f\"target:   {target}\")\n",
    "\n",
    "        # calculate the reward (SNR)\n",
    "        reward = SNR(target, filtered)\n",
    "        if np.isnan(reward):\n",
    "            raise Exception(f\"reward value is not a number...\\ntarget: {target}\\nfiltered: {filtered}\\nfilter: {filter}\")\n",
    "        \n",
    "        # if self.counter % 50 == 1:\n",
    "        print(f\"step: {self.counter}, SNR: {reward}, filter: {filter}\")\n",
    "        \n",
    "        # truncating the episode\n",
    "        truncated = False\n",
    "        if self.episode_counter == self.EPISODE_LENGTH or self.global_counter == self.MAX_TOTAL_NUM_OF_STEPS:\n",
    "            truncated = True\n",
    "        \n",
    "        info = {}\n",
    "\n",
    "        return self.state, reward, terminated, truncated, info\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------episode no: 1--------------------------------------------------\n",
      "audio name: 'vignesh'\n",
      "sampling rate: 44100 Hz\n",
      "audio shape: (136477,)\n",
      "data type: int16\n",
      "MONO audio file...\n",
      "generating the target signal...\n",
      "\ttruncating the spectrum at 5000Hz\n",
      "\tconverting from float64 to <class 'numpy.int16'>; array ranges from min: -13841.346435316103 (>=-32768) to max: 14399.410754652867 (<=32767)\n",
      "\ttrimming the audio signal...\n",
      "\t\ttruncating the audio at lower 0 and upper -1 indices\n",
      "generating the jammed signal...\n",
      "\tcreating a non-overlapping interference signal around 15000Hz with a bandwidth of 10000Hz\n",
      "\tconverting from float64 to <class 'numpy.int32'>; array ranges from min: -38983.15088455426 (>=-2147483648) to max: 41992.824003714835 (<=2147483647)\n",
      "\n",
      "--------------------------------------------------episode no: 2--------------------------------------------------\n",
      "audio name: 'vignesh'\n",
      "sampling rate: 44100 Hz\n",
      "audio shape: (136477,)\n",
      "data type: int16\n",
      "MONO audio file...\n",
      "generating the target signal...\n",
      "\ttruncating the spectrum at 5000Hz\n",
      "\tconverting from float64 to <class 'numpy.int16'>; array ranges from min: -13841.346435316103 (>=-32768) to max: 14399.410754652867 (<=32767)\n",
      "\ttrimming the audio signal...\n",
      "\t\ttruncating the audio at lower 0 and upper -1 indices\n",
      "generating the jammed signal...\n",
      "\tcreating a non-overlapping interference signal around 15000Hz with a bandwidth of 10000Hz\n",
      "\tconverting from float64 to <class 'numpy.int32'>; array ranges from min: -38983.15088455426 (>=-2147483648) to max: 41992.824003714835 (<=2147483647)\n",
      "step: 1, SNR: -8.391569504779769\n",
      "\n",
      "--------------------------------------------------episode no: 3--------------------------------------------------\n",
      "audio name: 'vignesh'\n",
      "sampling rate: 44100 Hz\n",
      "audio shape: (136477,)\n",
      "data type: int16\n",
      "MONO audio file...\n",
      "generating the target signal...\n",
      "\ttruncating the spectrum at 5000Hz\n",
      "\tconverting from float64 to <class 'numpy.int16'>; array ranges from min: -13841.346435316103 (>=-32768) to max: 14399.410754652867 (<=32767)\n",
      "\ttrimming the audio signal...\n",
      "\t\ttruncating the audio at lower 0 and upper -1 indices\n",
      "generating the jammed signal...\n",
      "\tcreating a non-overlapping interference signal around 15000Hz with a bandwidth of 10000Hz\n",
      "\tconverting from float64 to <class 'numpy.int32'>; array ranges from min: -38983.15088455426 (>=-2147483648) to max: 41992.824003714835 (<=2147483647)\n",
      "step: 1, SNR: -2.075026852032202\n",
      "step: 2, SNR: -5.671029830308349\n",
      "step: 3, SNR: -3.7724932655175616\n",
      "step: 4, SNR: -5.1568905878846945\n",
      "step: 5, SNR: -10.704413289638184\n",
      "step: 6, SNR: 1.1838641023544467\n",
      "step: 7, SNR: 3.9528688518911115\n",
      "step: 8, SNR: 2.569968757029599\n",
      "step: 9, SNR: -10.44249148640014\n",
      "step: 10, SNR: -3.3084990822051354\n"
     ]
    }
   ],
   "source": [
    "# checking the environment\n",
    "env = ReceiverEnv(N=5, S=100, cut_off_freq=5_000, interference_center_freq=15_000, audio_num=2)\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DDPG Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import MSE\n",
    "\n",
    "\n",
    "# =============================== REPLAY BUFFER ===============================\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, max_size, state_shape, n_actions):\n",
    "        self.mem_size = max_size\n",
    "        self.mem_cntr = 0\n",
    "\n",
    "        self.state_memory     = np.zeros((self.mem_size, *state_shape))\n",
    "        self.action_memory    = np.zeros((self.mem_size, n_actions))\n",
    "        self.reward_memory    = np.zeros(self.mem_size)\n",
    "        self.new_state_memory = np.zeros((self.mem_size, *state_shape))\n",
    "        self.terminal_memory  = np.zeros(self.mem_size, dtype=np.bool_) # using np.bool is really useful when pytorch is used.\n",
    "\n",
    "    def store_transition(self, state, action, reward, new_state, done):\n",
    "        index = self.mem_cntr % self.mem_size # implement a queue\n",
    "\n",
    "        self.state_memory[index]     = state\n",
    "        self.action_memory[index]    = action\n",
    "        self.reward_memory[index]    = reward\n",
    "        self.new_state_memory[index] = new_state\n",
    "        self.terminal_memory[index]  = done # problematic !!!\n",
    "\n",
    "        self.mem_cntr += 1\n",
    "\n",
    "    def sample_buffer(self, batch_size):\n",
    "        max_mem = min(self.mem_cntr, self.mem_size)\n",
    "\n",
    "        batch = np.random.choice(max_mem, batch_size, replace=False) # replace = False -> in a single batch, no element gets sampled more than once. \n",
    "\n",
    "        states     = self.state_memory[batch]\n",
    "        actions    = self.action_memory[batch]\n",
    "        rewards    = self.reward_memory[batch]\n",
    "        new_states = self.new_state_memory[batch]\n",
    "        dones      = self.terminal_memory[batch]\n",
    "\n",
    "        return states, actions, rewards, new_states, dones\n",
    "\n",
    "\n",
    "\n",
    "# =============================== CRITIC NETWORK ===============================\n",
    "class CriticNetwork(keras.Model):\n",
    "    def __init__(\n",
    "            self,\n",
    "            name, # model name (required by tf.keras.Model)\n",
    "            fc1_dims,\n",
    "            fc2_dims,\n",
    "            chkpt_dir='tmp/ddpg/'\n",
    "    ):\n",
    "        super(CriticNetwork, self).__init__()\n",
    "\n",
    "        self.model_name = name # do not use 'self.model'; it is a reserved variable name in tf\n",
    "        self.checkpoint_dir  = chkpt_dir\n",
    "        self.checkpoint_file = os.path.join(self.checkpoint_dir, self.model_name+'_ddpg.h5') \n",
    "        # extensions for saving keras models: legacy '.h5' -> TF 1.X, '.tf' -> TF 2.X\n",
    "\n",
    "        self.fc1_dims = fc1_dims\n",
    "        self.fc2_dims = fc2_dims\n",
    "\n",
    "        # # define network layers \n",
    "        # self.fc1 = Dense(self.fc1_dims, activation='relu')\n",
    "        # self.fc2 = Dense(self.fc2_dims, activation='relu')\n",
    "        # self.q   = Dense(1, activation=None)\n",
    "\n",
    "        # # define network layers \n",
    "        # self.hidden1  = Dense(self.fc1_dims, activation='relu', name=\"critic_hidden1\")\n",
    "        # self.hidden2  = Dense(self.fc2_dims, activation='relu', name=\"critic_hidden2\")\n",
    "        # # according to the paper, actions were not included until the 2nd hidden layer of Q\n",
    "        # self.hidden2_ = Dense(self.fc2_dims, activation='relu', name=\"critic_hidden2_\")\n",
    "        # self.q        = Dense(1, activation=None, name=\"q_value\") # change the activation appropriately\n",
    "\n",
    "        hidden1_initializer = RandomUniform(minval=-1/np.sqrt(self.fc1_dims), maxval=1/np.sqrt(self.fc1_dims))\n",
    "        hidden2_initializer = RandomUniform(minval=-1/np.sqrt(self.fc2_dims), maxval=1/np.sqrt(self.fc2_dims))\n",
    "        final_layer_initializer = RandomUniform(minval=-3*10**-4, maxval=3*10**-4)\n",
    "\n",
    "        # define network layers\n",
    "        self.hidden1 = Dense(\n",
    "            units=self.fc1_dims,\n",
    "            activation='relu',\n",
    "            kernel_initializer=hidden1_initializer,\n",
    "            bias_initializer=hidden1_initializer,\n",
    "            name=\"critic_hidden1\"\n",
    "        )\n",
    "        self.hidden2 = Dense(\n",
    "            units=self.fc2_dims, \n",
    "            activation='relu', \n",
    "            kernel_initializer=hidden2_initializer,\n",
    "            bias_initializer=hidden2_initializer,\n",
    "            name=\"critic_hidden2\"\n",
    "        )\n",
    "        self.hidden2_ = Dense(\n",
    "            units=self.fc2_dims, \n",
    "            activation='relu', \n",
    "            kernel_initializer=hidden2_initializer,\n",
    "            bias_initializer=hidden2_initializer,\n",
    "            name=\"critic_hidden2_\"\n",
    "        )\n",
    "        self.q = Dense(\n",
    "            units=1,\n",
    "            activation=None,\n",
    "            kernel_initializer=final_layer_initializer,\n",
    "            bias_initializer=final_layer_initializer,\n",
    "            name=\"q_value\"\n",
    "        )\n",
    "\n",
    "    def call(self, state, action):\n",
    "        # # temp1 = self.fc1(tf.concat([state, action], axis=1)) # axis 0 -> batch dimension\n",
    "        # temp1 = self.fc1(action)\n",
    "        # # ######################## PROBLEM ########################\n",
    "        # # according to the paper, actions were not included until the 2nd hidden layer of Q\n",
    "        # temp2 = self.fc2(temp1)\n",
    "        # q_value = self.q(temp2)\n",
    "\n",
    "        hidden1 = self.hidden1(state)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        hidden2_= self.hidden2_(action)\n",
    "        q_value = self.q(tf.concat([hidden2, hidden2_], axis=1))\n",
    "\n",
    "        return q_value\n",
    "\n",
    "# ================================ ACTOR NETWORK ===============================\n",
    "class ActorNetwork(keras.Model):\n",
    "    def __init__(\n",
    "            self,\n",
    "            name, # model name (required by tf.keras.Model)\n",
    "            n_actions, # action shape (dimenisonality of action space)\n",
    "            fc1_dims,\n",
    "            fc2_dims,\n",
    "            chkpt_dir='tmp/ddpg/'\n",
    "    ):\n",
    "        super(ActorNetwork, self).__init__()\n",
    "\n",
    "        self.model_name = name # do not use 'self.model'; it is a reserved variable name in tf\n",
    "        self.checkpoint_dir  = chkpt_dir\n",
    "        self.checkpoint_file = os.path.join(self.checkpoint_dir, self.model_name+'_ddpg.h5') \n",
    "\n",
    "        self.n_actions = n_actions\n",
    "        self.fc1_dims = fc1_dims\n",
    "        self.fc2_dims = fc2_dims\n",
    "\n",
    "        hidden1_initializer = RandomUniform(minval=-1/np.sqrt(self.fc1_dims), maxval=1/np.sqrt(self.fc1_dims))\n",
    "        hidden2_initializer = RandomUniform(minval=-1/np.sqrt(self.fc2_dims), maxval=1/np.sqrt(self.fc2_dims))\n",
    "        final_layer_initializer = RandomUniform(minval=-3*10**-4, maxval=3*10**-4)\n",
    "\n",
    "        # define network layers\n",
    "        self.hidden1 = Dense(\n",
    "            units=self.fc1_dims, \n",
    "            activation='relu', \n",
    "            kernel_initializer=hidden1_initializer,\n",
    "            bias_initializer=hidden1_initializer,\n",
    "            name='actor_hidden1'\n",
    "        )\n",
    "        self.hidden2 = Dense(\n",
    "            units=self.fc2_dims, \n",
    "            activation='relu', \n",
    "            kernel_initializer=hidden2_initializer,\n",
    "            bias_initializer=hidden2_initializer,\n",
    "            name='actor_hidden2'\n",
    "        )\n",
    "        self.mu = Dense(\n",
    "            units=n_actions,\n",
    "            activation='tanh', # limit the action in the range [-1, 1]\n",
    "            kernel_initializer=final_layer_initializer,\n",
    "            bias_initializer=final_layer_initializer,\n",
    "            name='action'\n",
    "        )\n",
    "\n",
    "        # self.hidden1 = Dense(self.fc1_dims,  activation='relu', name='actor_hidden1')\n",
    "        # self.hidden2 = Dense(self.fc2_dims,  activation='relu', name='actor_hidden2')\n",
    "        # self.mu  = Dense(self.n_actions, activation='tanh') # action is bounded by +/- 1\n",
    "\n",
    "    def call(self, state):\n",
    "        hidden1 = self.hidden1(state)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        action  = self.mu(hidden2)\n",
    "\n",
    "        return action\n",
    "\n",
    "\n",
    "\n",
    "# ================================== DDPG AGENT =================================\n",
    "class DDPGAgent:\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dims, # state shape\n",
    "            n_actions,  # dimensionality of actions\n",
    "            # env,        # gymnasium env\n",
    "            alpha,      # learning rate of actor\n",
    "            beta,       # learning rate of critic\n",
    "            gamma,      # discounting factor\n",
    "            tau,        # soft target update factor\n",
    "            critic_fc1,\n",
    "            critic_fc2,\n",
    "            actor_fc1,\n",
    "            actor_fc2,\n",
    "            batch_size,\n",
    "            buffer_size,\n",
    "            noise\n",
    "    ):\n",
    "        # set the class attributes\n",
    "        self.tau = tau\n",
    "        self.n_actions = n_actions\n",
    "        self.noise = noise\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma\n",
    "\n",
    "        # instantiate replay buffer\n",
    "        self.memory = ReplayBuffer(buffer_size, state_shape=input_dims, n_actions=n_actions)\n",
    "\n",
    "        # instantiate the networks\n",
    "        self.actor  = ActorNetwork(name=\"actor\", n_actions=n_actions, fc1_dims=actor_fc1, fc2_dims=actor_fc2)\n",
    "        self.critic = CriticNetwork(name=\"critic\", fc1_dims=critic_fc1, fc2_dims=critic_fc2)\n",
    "        self.target_actor  = ActorNetwork(name=\"target_actor\", n_actions=n_actions, fc1_dims=actor_fc1, fc2_dims=actor_fc2)\n",
    "        self.target_critic = CriticNetwork(name=\"target_critic\", fc1_dims=critic_fc1, fc2_dims=critic_fc2)\n",
    "\n",
    "        # compile networks\n",
    "        self.actor.compile(optimizer=Adam(learning_rate=alpha))\n",
    "        self.critic.compile(optimizer=Adam(learning_rate=beta))\n",
    "        # target networks do not require an optimizer or a learning rate since they are learned through soft updates.\n",
    "        # but, to use the networks in TF2, we have to compile them with an optimizer and a learning rate. \n",
    "        self.target_actor.compile(optimizer=Adam(learning_rate=alpha))\n",
    "        self.target_critic.compile(optimizer=Adam(learning_rate=beta))\n",
    "\n",
    "        # load identical weights to target networks\n",
    "        self.update_target_network_parameters(tau=1)\n",
    "\n",
    "    def update_target_network_parameters(self, tau=None):\n",
    "        if tau == None:\n",
    "            tau = self.tau\n",
    "\n",
    "        target_actor_weights = self.target_actor.weights\n",
    "        for i, actor_weights in enumerate(self.actor.weights):\n",
    "            target_actor_weights[i] = tau * actor_weights + (1-tau) * target_actor_weights[i]\n",
    "        self.target_actor.set_weights(target_actor_weights)\n",
    "\n",
    "        target_critic_weights = self.target_critic.weights\n",
    "        for i, critic_weights in enumerate(self.critic.weights):\n",
    "            target_critic_weights[i] = tau * critic_weights + (1-tau) * target_critic_weights[i]\n",
    "        self.target_critic.set_weights(target_critic_weights)\n",
    "\n",
    "    def remember(self, state, action, reward, new_state, done):\n",
    "        self.memory.store_transition(state, action, reward, new_state, done)\n",
    "\n",
    "    def save_models(self):\n",
    "        print(\"..... saving models .....\")\n",
    "        self.actor.save_weights(self.actor.checkpoint_file)\n",
    "        self.critic.save_weights(self.critic.checkpoint_file)\n",
    "        self.target_actor.save_weights(self.target_actor.checkpoint_file)\n",
    "        self.target_critic.save_weights(self.target_critic.checkpoint_file)\n",
    "\n",
    "    def load_models(self):\n",
    "        print(\"..... loading models .....\")\n",
    "        self.actor.load_weights(self.actor.checkpoint_file)\n",
    "        self.critic.load_weights(self.critic.checkpoint_file)\n",
    "        self.target_actor.load_weights(self.target_actor.checkpoint_file)\n",
    "        self.target_critic.load_weights(self.target_critic.checkpoint_file)\n",
    "\n",
    "    def choose_action(self, observation, evaluate=False):\n",
    "        state = tf.convert_to_tensor([observation], dtype=tf.float32) # introducing the batch dimension\n",
    "        action = self.actor(state) # 'action' would also have a batch dimension \n",
    "\n",
    "        if not evaluate:\n",
    "            # while training the agent, introduce an exploration noise\n",
    "            # here, the exploration noise is sampled from a normal distribution with zero mean and specified std deviation. \n",
    "            action += tf.random.normal(shape=[self.n_actions], mean=0.0, stddev=self.noise)\n",
    "            # when added the noise, the action can go beyond the action space limits; so, clip the actions.\n",
    "            # action = tf.clip_by_value(action, clip_value_max=1.0, clip_value_min=-1.0)\n",
    "\n",
    "        return action[0] # get rid of the batch dimension\n",
    "    \n",
    "    def learn(self):\n",
    "        if self.memory.mem_cntr < self.batch_size:\n",
    "            return\n",
    "        \n",
    "        state, action, reward, new_state, done = self.memory.sample_buffer(self.batch_size)\n",
    "\n",
    "        states     = tf.convert_to_tensor(state, dtype=tf.float32)\n",
    "        actions    = tf.convert_to_tensor(action, dtype=tf.float32)\n",
    "        rewards    = tf.convert_to_tensor(reward, dtype=tf.float32)\n",
    "        new_states = tf.convert_to_tensor(new_state, dtype=tf.float32)\n",
    "\n",
    "        # update the critic\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_actions = self.target_actor(new_states)\n",
    "            next_step_critic_values = tf.squeeze(self.target_critic(new_states, target_actions), axis=1)\n",
    "            critic_values = tf.squeeze(self.critic(states, actions), axis=1)\n",
    "            targets = rewards + self.gamma * next_step_critic_values * (1-done) # y_i\n",
    "            critic_loss = MSE(targets, critic_values)\n",
    "        \n",
    "        critic_network_gradients = tape.gradient(critic_loss, self.critic.trainable_variables)\n",
    "        self.critic.optimizer.apply_gradients(zip(critic_network_gradients, self.critic.trainable_variables))\n",
    "\n",
    "        # update the actor\n",
    "        with tf.GradientTape() as tape:\n",
    "            new_policy_actions = self.actor(states)\n",
    "            critic_values_ = -self.critic(states, new_policy_actions) # why - ? gradient ascent\n",
    "            actor_loss = tf.math.reduce_mean(critic_values_)\n",
    "\n",
    "        actor_network_gradients = tape.gradient(actor_loss, self.actor.trainable_variables)\n",
    "        self.actor.optimizer.apply_gradients(zip(actor_network_gradients, self.actor.trainable_variables))\n",
    "\n",
    "        # soft target updates\n",
    "        self.update_target_network_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------episode no: 1--------------------------------------------------\n",
      "audio name: 'arms_around_you-MONO'\n",
      "sampling rate: 44100 Hz\n",
      "audio shape: (8631296,)\n",
      "data type: int16\n",
      "MONO audio file...\n",
      "generating the target signal...\n",
      "\ttruncating the spectrum at 5000Hz\n",
      "\tconverting from float64 to <class 'numpy.int16'>; array ranges from min: -31316.608957868415 (>=-32768) to max: 31370.627685823245 (<=32767)\n",
      "\ttrimming the audio signal...\n",
      "\t\ttruncating the audio at lower 47706 and upper -33914 indices\n",
      "generating the jammed signal...\n",
      "\tcreating a non-overlapping interference signal around 15000Hz with a bandwidth of 10000Hz\n",
      "\tconverting from float64 to <class 'numpy.int32'>; array ranges from min: -49140.51895186492 (>=-2147483648) to max: 49149.0 (<=2147483647)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akila/.local/lib/python3.10/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1, SNR: 0.7290692853571407, filter: [ 0.00143222  0.00299184 -0.00074477  0.00299184  0.00143222]\n",
      "step: 2, SNR: 0.42456111508062977, filter: [ 0.00677466  0.00553398 -0.00629866  0.00553398  0.00677466]\n",
      "step: 3, SNR: 0.4325120662081958, filter: [ 0.04722238  0.01840266 -0.06468993  0.01840266  0.04722238]\n",
      "step: 4, SNR: -3.2733220173986304, filter: [-0.25352705  0.1582264  -0.24510954  0.1582264  -0.25352705]\n",
      "step: 5, SNR: -9.201490766517011, filter: [ 0.6690227   0.6628892  -0.65844804  0.6628892   0.6690227 ]\n",
      "step: 6, SNR: -3.970963743402973, filter: [ 0.16310526  0.57864743 -0.3603381   0.57864743  0.16310526]\n",
      "step: 7, SNR: -8.183349692963638, filter: [-0.058465    0.9501803  -0.83583087  0.9501803  -0.058465  ]\n",
      "step: 8, SNR: -5.278792372527169, filter: [ 0.18374714  0.5453346  -0.5655154   0.5453346   0.18374714]\n",
      "step: 9, SNR: -6.306578751487651, filter: [-0.02741856  0.41485313 -0.83150357  0.41485313 -0.02741856]\n",
      "step: 10, SNR: -9.596197076681927, filter: [-0.34893787 -0.27038673 -0.7766376  -0.27038673 -0.34893787]\n",
      "step: 11, SNR: -5.4958171478813345, filter: [-0.7623928   0.80986315 -0.5488285   0.80986315 -0.7623928 ]\n",
      "step: 12, SNR: 2.3665785702487434, filter: [-0.99052286  0.96214163  0.48966074  0.96214163 -0.99052286]\n",
      "step: 13, SNR: -8.056039678709233, filter: [-0.6922094   0.919988   -0.98240507  0.919988   -0.6922094 ]\n",
      "step: 14, SNR: -7.716595333926609, filter: [-0.15665151  0.1739274  -0.9907821   0.1739274  -0.15665151]\n",
      "step: 15, SNR: -8.076978662109628, filter: [-0.6595189  0.5657664 -0.8972066  0.5657664 -0.6595189]\n",
      "step: 16, SNR: -0.3753105591508539, filter: [-0.9996203  0.9151852  0.8034349  0.9151852 -0.9996203]\n",
      "step: 17, SNR: -4.719689076741039, filter: [ 0.15774843  0.67354435 -0.35384113  0.67354435  0.15774843]\n",
      "step: 18, SNR: -7.017949962561599, filter: [ 0.75408006  0.9534876  -0.9998789   0.9534876   0.75408006]\n",
      "step: 19, SNR: 7.936826812997646, filter: [-0.9746408   0.99940693 -0.8380057   0.99940693 -0.9746408 ]\n",
      "step: 20, SNR: -9.472988709900335, filter: [-0.9984447   0.5759658  -0.95416033  0.5759658  -0.9984447 ]\n",
      "step: 21, SNR: -0.29495339759985606, filter: [-0.99765426  0.9762863   0.8966929   0.9762863  -0.99765426]\n",
      "step: 22, SNR: -10.958465946099281, filter: [ 0.7438093   0.99497193 -0.21294886  0.99497193  0.7438093 ]\n",
      "step: 23, SNR: -7.685828265627915, filter: [ 0.96768475  0.99983186 -0.9976985   0.99983186  0.96768475]\n",
      "step: 24, SNR: -7.392832181940422, filter: [-0.8779087   0.95838046 -0.82777464  0.95838046 -0.8779087 ]\n",
      "step: 25, SNR: -4.831668256650331, filter: [-0.41253775  0.4699122  -0.5355974   0.4699122  -0.41253775]\n",
      "step: 26, SNR: -1.5926159093440793, filter: [-0.9943027   0.87416863  0.852946    0.87416863 -0.9943027 ]\n",
      "step: 27, SNR: -7.7397020543238435, filter: [-0.80068904  0.9881263  -0.9207181   0.9881263  -0.80068904]\n",
      "step: 28, SNR: -6.273679399625465, filter: [-0.9073735  0.4400504  0.9569027  0.4400504 -0.9073735]\n",
      "step: 29, SNR: -13.06343680093204, filter: [ 0.99321246  0.97360593 -0.9912745   0.97360593  0.99321246]\n",
      "step: 30, SNR: -2.670429183935554, filter: [-0.2529424   0.57060575 -0.3890555   0.57060575 -0.2529424 ]\n",
      "step: 31, SNR: -8.487191549375602, filter: [-0.9585006   0.94798076 -0.9949581   0.94798076 -0.9585006 ]\n",
      "step: 32, SNR: -3.2141396460468776, filter: [-0.9831602   0.9021199  -0.18736629  0.9021199  -0.9831602 ]\n",
      "step: 33, SNR: -12.9897597947785, filter: [ 0.94944215  0.9938725  -0.9937792   0.9938725   0.94944215]\n",
      "step: 34, SNR: -10.543144726177914, filter: [ 0.9236102   0.49860603 -0.97607607  0.49860603  0.9236102 ]\n",
      "step: 35, SNR: -8.194384610919567, filter: [-0.4473402   0.99979025 -0.9968062   0.99979025 -0.4473402 ]\n",
      "step: 36, SNR: -7.896569457772178, filter: [-0.9855417   0.62435794 -0.6572173   0.62435794 -0.9855417 ]\n",
      "step: 37, SNR: -6.308171443815159, filter: [-0.33526805  0.76884276 -0.76749724  0.76884276 -0.33526805]\n",
      "step: 38, SNR: -9.820948941589366, filter: [-0.8593943   0.32336348 -0.9201428   0.32336348 -0.8593943 ]\n",
      "step: 39, SNR: -10.047490431580652, filter: [ 0.19247134  0.9998738  -0.9982053   0.9998738   0.19247134]\n",
      "step: 40, SNR: -5.6832792733200925, filter: [-0.61198705  0.5148333  -0.5424665   0.5148333  -0.61198705]\n",
      "step: 41, SNR: -2.1507343595483173, filter: [-0.89840734  0.7373056   0.09154386  0.7373056  -0.89840734]\n",
      "step: 42, SNR: -11.636828479470843, filter: [-0.80063784 -0.14864126 -0.92395717 -0.14864126 -0.80063784]\n",
      "step: 43, SNR: -9.40246760996587, filter: [ 0.04009126  0.9969357  -0.99159443  0.9969357   0.04009126]\n",
      "step: 44, SNR: -0.7933009327090557, filter: [-0.14799897  0.36965582 -0.24402045  0.36965582 -0.14799897]\n",
      "step: 45, SNR: -6.862573817777137, filter: [-0.61980385  0.75923705 -0.8218391   0.75923705 -0.61980385]\n",
      "step: 46, SNR: -2.5180958584988766, filter: [-0.6191755  0.9061335 -0.2781984  0.9061335 -0.6191755]\n",
      "step: 47, SNR: -8.45075277539199, filter: [-0.26121467  0.99559146 -0.9965684   0.99559146 -0.26121467]\n",
      "step: 48, SNR: -9.236898709632909, filter: [-0.6096422  -0.26393598  0.2229015  -0.26393598 -0.6096422 ]\n",
      "step: 49, SNR: -13.031365446595027, filter: [-0.8229172  -0.47346434 -0.8639695  -0.47346434 -0.8229172 ]\n",
      "step: 50, SNR: -7.598654928727015, filter: [-0.85666674  0.63564557 -0.70000345  0.63564557 -0.85666674]\n",
      "step: 51, SNR: -8.189846359715329, filter: [-0.40532613  0.9999827  -0.9998821   0.9999827  -0.40532613]\n",
      "step: 52, SNR: -4.272573878093777, filter: [ 0.03683076  0.28770724 -0.5897013   0.28770724  0.03683076]\n",
      "step: 53, SNR: -7.558865249281155, filter: [-0.85885835  0.6373224  -0.73859245  0.6373224  -0.85885835]\n",
      "step: 54, SNR: -5.894577579787546, filter: [-0.37931943  0.02231396 -0.2588377   0.02231396 -0.37931943]\n",
      "step: 55, SNR: -8.427464295341942, filter: [-0.90849245  0.9060646  -0.99964833  0.9060646  -0.90849245]\n",
      "step: 56, SNR: -11.604033948486316, filter: [ 0.7185142   0.93314445 -0.9199358   0.93314445  0.7185142 ]\n",
      "step: 57, SNR: -6.721100324876642, filter: [-0.8858926   0.8284883  -0.69983464  0.8284883  -0.8858926 ]\n",
      "step: 58, SNR: -5.959731060672013, filter: [0.12656966 0.9925457  0.52704734 0.9925457  0.12656966]\n",
      "step: 59, SNR: -8.55652389317532, filter: [-0.9859147   0.94043374 -0.9940291   0.94043374 -0.9859147 ]\n",
      "step: 60, SNR: -8.290531967176861, filter: [-0.08907004 -0.1220915  -0.9470525  -0.1220915  -0.08907004]\n",
      "step: 61, SNR: -5.440393559856711, filter: [-0.8911268   0.65042675 -0.32188988  0.65042675 -0.8911268 ]\n",
      "step: 62, SNR: -0.4014881312852542, filter: [-0.30381557  0.99192494  0.55093586  0.99192494 -0.30381557]\n",
      "step: 63, SNR: -7.5313007622674855, filter: [-0.9744434   0.99135196 -0.81712526  0.99135196 -0.9744434 ]\n",
      "step: 64, SNR: -7.018117292033298, filter: [ 0.28038567 -0.06448142 -0.9721136  -0.06448142  0.28038567]\n",
      "step: 65, SNR: -4.298363456858916, filter: [-0.5677894  0.6043574 -0.4525505  0.6043574 -0.5677894]\n",
      "step: 66, SNR: -6.814162970801558, filter: [ 0.04184072  0.90725625 -0.4552286   0.90725625  0.04184072]\n",
      "step: 67, SNR: -9.072205128335241, filter: [-0.9734337  0.6179477 -0.9065148  0.6179477 -0.9734337]\n",
      "step: 68, SNR: -12.903218921624873, filter: [ 0.95946884  0.99706084 -0.93177545  0.99706084  0.95946884]\n",
      "step: 69, SNR: -4.488019920114487, filter: [-0.85340655  0.85224515 -0.418829    0.85224515 -0.85340655]\n",
      "step: 70, SNR: 1.1247974361230975, filter: [-0.5180955   0.74837327  0.00460246  0.74837327 -0.5180955 ]\n",
      "step: 71, SNR: -11.378588464263412, filter: [-0.99072456 -0.6684796  -0.50685394 -0.6684796  -0.99072456]\n",
      "step: 72, SNR: -10.868661069757408, filter: [ 0.7393837   0.75933623 -0.91543067  0.75933623  0.7393837 ]\n",
      "step: 73, SNR: 0.4167008473828778, filter: [-0.7300196   0.95143753 -0.04907114  0.95143753 -0.7300196 ]\n",
      "step: 74, SNR: -6.877304960518133, filter: [-0.51861084  0.6451012  -0.8185786   0.6451012  -0.51861084]\n",
      "step: 75, SNR: -12.581610709143234, filter: [-0.9065027  -0.51580375 -0.01542066 -0.51580375 -0.9065027 ]\n",
      "step: 76, SNR: -10.940887102996008, filter: [ 0.87631893  0.7032081  -0.7710123   0.7032081   0.87631893]\n",
      "step: 77, SNR: -4.859534995013615, filter: [-0.63032687  0.5328395  -0.4215511   0.5328395  -0.63032687]\n",
      "step: 78, SNR: -8.090934649490563, filter: [ 0.2253122   0.9411771  -0.52370626  0.9411771   0.2253122 ]\n",
      "step: 79, SNR: -10.729968715311545, filter: [-0.8704969  -0.13350102 -0.36157054 -0.13350102 -0.8704969 ]\n",
      "step: 80, SNR: -6.571239834901618, filter: [0.20060284 0.97591335 0.18664353 0.97591335 0.20060284]\n",
      "step: 81, SNR: -5.1391074712803135, filter: [-0.58033454  0.46031463 -0.44497234  0.46031463 -0.58033454]\n",
      "step: 82, SNR: -6.651650000905547, filter: [-0.3025553   0.61264837 -0.84233     0.61264837 -0.3025553 ]\n",
      "step: 83, SNR: -10.359172967425385, filter: [-0.9661141  -0.09583668  0.33022365 -0.09583668 -0.9661141 ]\n",
      "step: 84, SNR: -2.634500572704389, filter: [-0.4036155   0.96259815 -0.25155267  0.96259815 -0.4036155 ]\n",
      "step: 85, SNR: -3.1085986523970703, filter: [0.24021043 0.46304232 0.9732499  0.46304232 0.24021043]\n",
      "step: 86, SNR: -7.376065268878797, filter: [-0.56095093  0.7815756  -0.89639956  0.7815756  -0.56095093]\n",
      "step: 87, SNR: -5.355056535114539, filter: [0.17085037 0.87302107 0.03409473 0.87302107 0.17085037]\n",
      "step: 88, SNR: -8.033520774714088, filter: [-0.27744415  0.9484288  -0.94882756  0.9484288  -0.27744415]\n",
      "step: 89, SNR: -4.838110092049597, filter: [-0.8533282   0.53527606  0.991655    0.53527606 -0.8533282 ]\n",
      "step: 90, SNR: -7.9277580528785005, filter: [ 0.2247951   0.67517143 -0.8538053   0.67517143  0.2247951 ]\n",
      "step: 91, SNR: -6.947419393883425, filter: [ 0.9927489   0.99162525 -0.9693623   0.99162525  0.9927489 ]\n",
      "step: 92, SNR: -7.682315211856233, filter: [-0.9232061   0.47094995 -0.495408    0.47094995 -0.9232061 ]\n",
      "step: 93, SNR: -3.024866308879377, filter: [-0.9650623   0.7834146   0.95251155  0.7834146  -0.9650623 ]\n",
      "step: 94, SNR: -8.575329461220267, filter: [ 0.5376168  0.6219309 -0.7393968  0.6219309  0.5376168]\n",
      "step: 95, SNR: -9.135505278743505, filter: [ 0.9434622  0.9924673 -0.987886   0.9924673  0.9434622]\n",
      "step: 96, SNR: -5.476095725396886, filter: [-0.5486287   0.26306215 -0.29441866  0.26306215 -0.5486287 ]\n",
      "step: 97, SNR: -2.5827872949878357, filter: [-0.9979871   0.8564628   0.97869754  0.8564628  -0.9979871 ]\n",
      "step: 98, SNR: -6.530316744052458, filter: [-0.6676432   0.87836725 -0.72823554  0.87836725 -0.6676432 ]\n",
      "step: 99, SNR: -10.910041298285416, filter: [ 0.99684256  0.9851672  -0.99830824  0.9851672   0.99684256]\n",
      "step: 100, SNR: -8.27144352790381, filter: [-0.73629993  0.6578249  -0.9648995   0.6578249  -0.73629993]\n",
      "step: 101, SNR: -1.8514183490439904, filter: [-0.9914832   0.78757256  0.68737924  0.78757256 -0.9914832 ]\n",
      "step: 102, SNR: -8.204332540179124, filter: [-0.85948914  0.56420976 -0.77443635  0.56420976 -0.85948914]\n",
      "step: 103, SNR: -7.500919314901646, filter: [ 0.98492795  0.98928523 -0.9992814   0.98928523  0.98492795]\n",
      "step: 104, SNR: -6.843437166209522, filter: [-0.5294337  0.463678  -0.7520262  0.463678  -0.5294337]\n",
      "step: 105, SNR: -5.706117394188936, filter: [-0.9441386   0.8163586  -0.47454542  0.8163586  -0.9441386 ]\n",
      "step: 106, SNR: -7.20009870359437, filter: [-0.8642323  0.7392519 -0.7074324  0.7392519 -0.8642323]\n",
      "step: 107, SNR: -10.851067892188166, filter: [ 0.88932246  0.58565015 -0.99188536  0.58565015  0.88932246]\n",
      "step: 108, SNR: -8.642328782418716, filter: [-0.7752485   0.25992158 -0.6460233   0.25992158 -0.7752485 ]\n",
      "step: 109, SNR: -3.116464068394726, filter: [-0.92009985  0.84098506 -0.17030965  0.84098506 -0.92009985]\n",
      "step: 110, SNR: -7.991953245174282, filter: [-0.6643075  0.9852309 -0.9809337  0.9852309 -0.6643075]\n",
      "step: 111, SNR: -9.606275271860609, filter: [ 0.9878659  0.2554543 -0.9959303  0.2554543  0.9878659]\n",
      "step: 112, SNR: -10.25116407430734, filter: [-0.9647086   0.16612217 -0.65358293  0.16612217 -0.9647086 ]\n",
      "step: 113, SNR: -4.396340203873599, filter: [-0.8174741   0.49264747  0.02881535  0.49264747 -0.8174741 ]\n",
      "step: 114, SNR: -7.8689317558105785, filter: [-0.16374195  0.90241736 -0.89099616  0.90241736 -0.16374195]\n",
      "step: 115, SNR: -9.70930567019497, filter: [ 0.7222734  0.5054298 -0.9830655  0.5054298  0.7222734]\n",
      "step: 116, SNR: -7.197018203364419, filter: [-0.89184284  0.5566547  -0.51734537  0.5566547  -0.89184284]\n",
      "step: 117, SNR: -5.630386264974463, filter: [-0.98292816  0.55913126 -0.02908468  0.55913126 -0.98292816]\n",
      "step: 118, SNR: -7.614117158908026, filter: [-0.5094388   0.94387245 -0.9365724   0.94387245 -0.5094388 ]\n",
      "step: 119, SNR: -8.149164954609073, filter: [ 0.24498744 -0.42696252 -0.97267014 -0.42696252  0.24498744]\n",
      "step: 120, SNR: -9.912741691070906, filter: [ 0.4292249   0.86769444 -0.8580947   0.86769444  0.4292249 ]\n",
      "step: 121, SNR: -3.8839921165899147, filter: [-0.9203302   0.82499915 -0.25780424  0.82499915 -0.9203302 ]\n",
      "step: 122, SNR: -7.749616099519252, filter: [-0.7168433  0.9949542 -0.9474     0.9949542 -0.7168433]\n",
      "step: 123, SNR: -13.51031446518746, filter: [-0.41874182 -0.95176786 -0.9643512  -0.95176786 -0.41874182]\n",
      "step: 124, SNR: 3.2692731780308977, filter: [-0.19343004  0.35879907  0.04301194  0.35879907 -0.19343004]\n",
      "step: 125, SNR: -5.226746574110521, filter: [-0.7104947   0.42787853 -0.24310714  0.42787853 -0.7104947 ]\n",
      "step: 126, SNR: -7.7475137151306654, filter: [-0.520208    0.99504584 -0.9331214   0.99504584 -0.520208  ]\n",
      "step: 127, SNR: -13.902793915427754, filter: [-0.8577869  -0.6137929  -0.98562986 -0.6137929  -0.8577869 ]\n",
      "step: 128, SNR: -1.8701677561909977, filter: [-0.33933163  0.7459763  -0.2628363   0.7459763  -0.33933163]\n",
      "step: 129, SNR: -4.9213824671120285, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 130, SNR: -5.151855003506807, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 131, SNR: -4.883661325029846, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 132, SNR: -5.253161227178012, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 133, SNR: -4.9113784149808986, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 134, SNR: -5.379857803143917, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 135, SNR: -4.922885474077614, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 136, SNR: -5.241429482920507, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 137, SNR: -4.969330440881565, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 138, SNR: -5.342044894917326, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 139, SNR: -4.877625786451645, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 140, SNR: -5.145004239160597, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 141, SNR: -4.92370496636343, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 142, SNR: -5.267536506079628, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 143, SNR: -4.827535751517502, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 144, SNR: -5.333043479556803, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 145, SNR: -4.877192633310931, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 146, SNR: -5.1678746832129505, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 147, SNR: -4.930182414661777, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 148, SNR: -5.28358475974151, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 149, SNR: -4.90536341549508, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 150, SNR: -5.242203875825191, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 151, SNR: -4.942449264310805, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 152, SNR: -5.1899607736475195, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 153, SNR: -4.926333493569731, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 154, SNR: -5.194509239692669, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 155, SNR: -4.8819029612154266, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 156, SNR: -5.565247822046315, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 157, SNR: -4.950123292460571, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 158, SNR: -5.170592419857474, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 159, SNR: -4.903095550238912, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 160, SNR: -5.453295167129588, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 161, SNR: -5.025195349404879, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 162, SNR: -5.077274374038452, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 163, SNR: -4.949182251181944, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 164, SNR: -5.416923307969316, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 165, SNR: -5.00173355794421, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 166, SNR: -5.085670004527945, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 167, SNR: -4.954462606083703, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 168, SNR: -5.40185504933877, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 169, SNR: -4.965699306326862, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 170, SNR: -5.231471698997696, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 171, SNR: -4.967898821780158, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 172, SNR: -5.361364929172369, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 173, SNR: -4.988758804424916, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 174, SNR: -5.156597648663687, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 175, SNR: -4.878502632111578, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 176, SNR: -5.302697647843212, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 177, SNR: -4.949012215400192, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 178, SNR: -5.199415722315603, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 179, SNR: -4.9369784608744425, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 180, SNR: -5.0589926299349735, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 181, SNR: -4.977907771412563, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 182, SNR: -5.226498922070904, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 183, SNR: -5.004344326511974, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 184, SNR: -5.084247583869801, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 185, SNR: -4.973384004355327, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 186, SNR: -5.212458681599353, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 187, SNR: -4.94106212096269, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 188, SNR: -4.998155327639454, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 189, SNR: -4.976254643672434, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 190, SNR: -5.248807328234191, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 191, SNR: -4.923489338635051, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 192, SNR: -4.935331227629792, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 193, SNR: -5.055441053774139, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 194, SNR: -5.155439931206891, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 195, SNR: -4.939268792726904, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 196, SNR: -4.976810824537109, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 197, SNR: -5.0142563013502315, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 198, SNR: -5.126778332597518, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 199, SNR: -4.980503872636531, filter: [ 1. -1.  1. -1.  1.]\n",
      "step: 200, SNR: -4.985335086387762, filter: [ 1. -1.  1. -1.  1.]\n"
     ]
    }
   ],
   "source": [
    "model = DDPGAgent(\n",
    "    input_dims  = env.observation_space.shape,\n",
    "    n_actions   = env.action_space.shape[0],\n",
    "    alpha       = 0.01,\n",
    "    beta        = 0.1,\n",
    "    gamma       = 0.5,\n",
    "    tau         = 0.001,\n",
    "    critic_fc1  = 1024,\n",
    "    critic_fc2  = 512,\n",
    "    actor_fc1   = 1024,\n",
    "    actor_fc2   = 1024,\n",
    "    batch_size  = 128,\n",
    "    buffer_size = 10**3,\n",
    "    noise       = 0\n",
    ")\n",
    "keras.backend.clear_session()\n",
    "\n",
    "max_num_steps = 200\n",
    "reward_history = []\n",
    "action_history = []\n",
    "step_count = 0\n",
    "\n",
    "# reset the environment\n",
    "env = ReceiverEnv(N=5, S=100, cut_off_freq=5_000, interference_center_freq=15_000, audio_num=2)\n",
    "state, _ = env.reset(options='reset_all')\n",
    "done = False\n",
    "while not done:\n",
    "    # feed the state to the agent (model) and get an action\n",
    "    action = model.choose_action(state) # this includes the exploration noise\n",
    "\n",
    "    # take the action in the environment\n",
    "    next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "    done = terminated | truncated\n",
    "    step_count += 1\n",
    "\n",
    "    # store the transition in the replay buffer of the DDPG agent\n",
    "    model.remember(state, action, reward, next_state, done)\n",
    "\n",
    "    # train the model\n",
    "    model.learn()\n",
    "\n",
    "    # set the `next_state` as `state`\n",
    "    state = next_state\n",
    "\n",
    "    # keep track of the `reward`\n",
    "    reward_history.append(reward)\n",
    "\n",
    "    action_history.append(action)\n",
    "     \n",
    "    if step_count >= max_num_steps:\n",
    "        done = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86542463, 0.63167137, 0.61965966], dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(np.array(np.abs(action_history)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 1.5131151e-04, -1.7013946e-04],\n",
       "       [-7.7674995e-05, -2.1894986e-05]], dtype=float32)>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing - initializers\n",
    "\n",
    "final_layer_initializer = RandomUniform(minval=-3*10**-4, maxval=3*10**-4)\n",
    "final_layer_initializer(shape=(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 104)]             0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 128)               13440     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30339 (118.51 KB)\n",
      "Trainable params: 30339 (118.51 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akila/.local/lib/python3.10/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 109ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.00043901,  0.00019638,  0.00028144]], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actor\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "\n",
    "input_shape = env.observation_space.shape\n",
    "fc1 = 128\n",
    "fc2 = 128\n",
    "n_actions = 3\n",
    "\n",
    "hidden1_initializer = RandomUniform(minval=-1/np.sqrt(input_shape[0]), maxval=1/np.sqrt(input_shape[0]))\n",
    "hidden2_initializer = RandomUniform(minval=-1/np.sqrt(fc1), maxval=1/np.sqrt(fc1))\n",
    "final_layer_initializer = RandomUniform(minval=-3*10**-4, maxval=3*10**-4)\n",
    "\n",
    "input = Input(shape=input_shape)\n",
    "hidden1 = Dense(\n",
    "            units=fc1, \n",
    "            activation='relu', \n",
    "            kernel_initializer=hidden1_initializer,\n",
    "            bias_initializer=hidden1_initializer\n",
    "            )(input)\n",
    "hidden2 = Dense(\n",
    "            units=fc2, \n",
    "            activation='relu', \n",
    "            kernel_initializer=hidden2_initializer,\n",
    "            bias_initializer=hidden2_initializer\n",
    "            )(hidden1)\n",
    "output = Dense(\n",
    "            units=n_actions,\n",
    "            activation='tanh', # limit the action in the range [-1, 1]\n",
    "            kernel_initializer=final_layer_initializer,\n",
    "            bias_initializer=final_layer_initializer\n",
    "            )(hidden2)\n",
    "\n",
    "actor_network = Model(inputs=input, outputs=output)\n",
    "actor_network.compile(optimizer=Adam(learning_rate=0.001))\n",
    "actor_network.summary()\n",
    "\n",
    "# predict\n",
    "dummy_input = np.expand_dims(env.observation_space.sample(), axis=0)\n",
    "actor_network.predict(dummy_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
