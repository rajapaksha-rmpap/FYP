{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 10)                50        \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 182 (728.00 Byte)\n",
      "Trainable params: 182 (728.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# how to build a model?\n",
    "\n",
    "# method 1\n",
    "model1 = keras.Sequential([\n",
    "    Input(shape=(4, )), # Input layer: don't include batch dimension\n",
    "    # Dense(10, activation='relu', input_shape=(4, )) # Input layer\n",
    "    Dense(10, activation='relu'), # 1st hidden layer\n",
    "    Dense(10, activation='relu'), # 2nd hidden layer\n",
    "    Dense(2, activation='softmax')  # Output layer\n",
    "])\n",
    "print(model1.summary())\n",
    "\n",
    "# method 2\n",
    "model2 = keras.Sequential()\n",
    "model2.add(Input(shape=(4, ))) # Input layer\n",
    "model2.add(Dense(10, activation='relu'))\n",
    "model2.add(Dense(10, activation='relu'))\n",
    "model2.add(Dense(2, activation='softmax'))\n",
    "# print(model2.summary())\n",
    "\n",
    "# method 3\n",
    "input = Input(shape=(4, )) # Input layer\n",
    "hidden1 = Dense(10, activation='relu')(input)\n",
    "hidden2 = Dense(10, activation='relu')(hidden1)\n",
    "output = Dense(2, activation='softmax')(hidden2)\n",
    "\n",
    "model3 = keras.Model(inputs=input, outputs=output)\n",
    "# print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the models\n",
    "model1.compile(optimizer=Adam(learning_rate=0.001)) # (learning_rate=0.001)\n",
    "model2.compile(optimizer=Adam(learning_rate=0.001))\n",
    "model3.compile(optimizer=Adam(learning_rate=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_30/kernel:0' shape=(4, 10) dtype=float32, numpy=\n",
       " array([[ 0.09325033, -0.20294166,  0.09878844,  0.64578044, -0.63944006,\n",
       "          0.59449995, -0.20723858,  0.20183253, -0.5635318 ,  0.34384525],\n",
       "        [-0.38034323, -0.27349865,  0.563905  ,  0.2688073 , -0.47609037,\n",
       "         -0.2881711 , -0.17242974, -0.23937953, -0.31050965, -0.03825796],\n",
       "        [ 0.1402908 ,  0.4667977 , -0.5144813 ,  0.6535865 , -0.49980918,\n",
       "         -0.16105825,  0.07418245,  0.4692515 ,  0.55717576, -0.07125938],\n",
       "        [ 0.51424706,  0.5204617 , -0.25585568,  0.6091745 , -0.29669598,\n",
       "          0.55733025, -0.23244232,  0.02863443,  0.5796647 , -0.1983588 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_30/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_31/kernel:0' shape=(10, 10) dtype=float32, numpy=\n",
       " array([[ 0.00877482, -0.5467702 , -0.20952618,  0.15147287,  0.47414947,\n",
       "         -0.38977093, -0.2840522 , -0.42686605,  0.12622064,  0.06100255],\n",
       "        [-0.5154436 , -0.4115031 , -0.38521916, -0.22246829,  0.03368002,\n",
       "          0.3541202 , -0.52691627, -0.36731762,  0.19487286, -0.2544888 ],\n",
       "        [ 0.25721222,  0.32916993, -0.48710594, -0.10627243, -0.42297494,\n",
       "          0.4921707 ,  0.1756376 , -0.4784292 ,  0.25991285, -0.39584988],\n",
       "        [ 0.04083908,  0.18157005, -0.23567471,  0.54294586,  0.22654718,\n",
       "         -0.51484674, -0.26914695, -0.5096081 ,  0.02145666, -0.07974598],\n",
       "        [ 0.08198291, -0.0157581 , -0.24040484, -0.2774843 ,  0.39945865,\n",
       "          0.06635177, -0.11223921, -0.43177706,  0.20842797,  0.28880566],\n",
       "        [ 0.21140963, -0.00144988, -0.23771697,  0.4399116 ,  0.03524172,\n",
       "          0.5036986 , -0.41321734, -0.14196882,  0.4677354 , -0.3185792 ],\n",
       "        [-0.16760129,  0.04608268,  0.4716165 , -0.41190192,  0.35694087,\n",
       "          0.4737488 ,  0.31794465,  0.2114377 ,  0.36359107, -0.29738945],\n",
       "        [ 0.04798847, -0.08059308,  0.19572365,  0.18235636,  0.11657965,\n",
       "         -0.5446334 ,  0.28909665, -0.06894156, -0.4860017 , -0.23708531],\n",
       "        [ 0.0159139 , -0.17458364,  0.29269552, -0.19588202, -0.54305315,\n",
       "         -0.2650101 ,  0.09495819,  0.45679152,  0.09602666,  0.3673163 ],\n",
       "        [ 0.4665736 , -0.35794395, -0.09558308, -0.4147371 , -0.13810122,\n",
       "         -0.26955464,  0.13259226,  0.30348372,  0.08399868, -0.45480114]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_31/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_32/kernel:0' shape=(10, 2) dtype=float32, numpy=\n",
       " array([[-0.48686337, -0.00371969],\n",
       "        [ 0.5415258 ,  0.36908585],\n",
       "        [-0.4883449 , -0.01647335],\n",
       "        [-0.17704624, -0.2004044 ],\n",
       "        [ 0.17471504, -0.24931952],\n",
       "        [ 0.6866457 , -0.5489155 ],\n",
       "        [ 0.53725296,  0.5915622 ],\n",
       "        [-0.63813174, -0.04360932],\n",
       "        [ 0.3052351 ,  0.52458376],\n",
       "        [ 0.22982675,  0.427746  ]], dtype=float32)>,\n",
       " <tf.Variable 'dense_32/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the weights from a model\n",
    "w = model1.weights\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_33/kernel:0' shape=(4, 10) dtype=float32, numpy=\n",
       " array([[ 0.35586226, -0.33619928, -0.02299941, -0.5222022 , -0.535032  ,\n",
       "          0.5360223 ,  0.01422513, -0.34894523, -0.4169281 ,  0.1286267 ],\n",
       "        [-0.03263259, -0.5042227 ,  0.12080592,  0.45262587, -0.5033421 ,\n",
       "          0.3105017 , -0.01988155,  0.1636414 ,  0.08690733,  0.08733904],\n",
       "        [-0.22268224, -0.15547273, -0.44754276, -0.3551866 , -0.24212393,\n",
       "         -0.23959151, -0.6357609 ,  0.09109968,  0.5155623 , -0.08088726],\n",
       "        [ 0.5672389 , -0.08094394,  0.47193754,  0.39443612,  0.6393901 ,\n",
       "         -0.2700722 , -0.1607717 , -0.4621228 ,  0.4997052 ,  0.45624936]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_33/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_34/kernel:0' shape=(10, 10) dtype=float32, numpy=\n",
       " array([[-0.44231752,  0.37223488, -0.09476244, -0.43646434, -0.2377944 ,\n",
       "          0.24874872, -0.18379813,  0.16191655,  0.01025933,  0.01604682],\n",
       "        [-0.46852246,  0.46845615,  0.46627605,  0.00219518,  0.08155763,\n",
       "         -0.01172388,  0.28318977, -0.42726877,  0.40787852, -0.46238762],\n",
       "        [ 0.25388718, -0.40413105, -0.5141841 ,  0.1035617 , -0.49318883,\n",
       "         -0.25300822, -0.5168302 ,  0.24291277,  0.40655166,  0.09712321],\n",
       "        [ 0.41340697,  0.50696814, -0.00121629, -0.2857245 , -0.3846899 ,\n",
       "          0.13624662, -0.25868744, -0.3659113 ,  0.16117507, -0.2851614 ],\n",
       "        [ 0.21831363, -0.3927645 ,  0.2022773 , -0.5232286 ,  0.07168794,\n",
       "          0.18671483,  0.35210496,  0.03566915,  0.24921101,  0.19100511],\n",
       "        [-0.05360529,  0.17812985,  0.32355917, -0.43105516,  0.20441228,\n",
       "         -0.331167  ,  0.1382792 ,  0.15545404, -0.17574587, -0.35299665],\n",
       "        [-0.0966655 , -0.35981196,  0.04003245,  0.12686944,  0.42853862,\n",
       "          0.06169814, -0.08814365, -0.11771527,  0.19407785,  0.37618333],\n",
       "        [ 0.10346568,  0.05543405,  0.37123233, -0.26459873, -0.28882724,\n",
       "         -0.5147357 , -0.19906864, -0.47721708,  0.11510676,  0.21561676],\n",
       "        [-0.44018033, -0.16745567, -0.15675262,  0.5223632 ,  0.31574124,\n",
       "          0.48809898, -0.15547663, -0.48884928,  0.18840241,  0.4797107 ],\n",
       "        [-0.17526141, -0.54074556, -0.18867207,  0.36397523, -0.35309273,\n",
       "          0.00846869,  0.44661212,  0.23719776, -0.05974302, -0.1399732 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_34/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_35/kernel:0' shape=(10, 2) dtype=float32, numpy=\n",
       " array([[ 0.6964802 , -0.1254273 ],\n",
       "        [ 0.28187072, -0.20903403],\n",
       "        [ 0.63258487,  0.38759333],\n",
       "        [-0.18842101, -0.20160997],\n",
       "        [ 0.2739275 , -0.64392275],\n",
       "        [-0.23660228,  0.21720898],\n",
       "        [-0.01195168,  0.6610163 ],\n",
       "        [ 0.18810457,  0.2224443 ],\n",
       "        [-0.52269727, -0.52088416],\n",
       "        [-0.0574497 , -0.35489973]], dtype=float32)>,\n",
       " <tf.Variable 'dense_35/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = model2.weights\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.ops.resource_variable_ops.ResourceVariable"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================== REPLAY BUFFER ===============================\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, max_size, state_shape, n_actions):\n",
    "        self.mem_size = max_size\n",
    "        self.mem_cntr = 0\n",
    "\n",
    "        self.state_memory     = np.zeros((self.mem_size, *state_shape))\n",
    "        self.action_memory    = np.zeros((self.mem_size, n_actions))\n",
    "        self.reward_memory    = np.zeros(self.mem_size)\n",
    "        self.new_state_memory = np.zeros((self.mem_size, *state_shape))\n",
    "        self.terminal_memory  = np.zeros(self.mem_size, dtype=np.bool) # using np.bool is really useful when pytorch is used.\n",
    "\n",
    "    def store_transition(self, state, action, reward, new_state, done):\n",
    "        index = self.mem_cntr % self.mem_size # implement a queue\n",
    "\n",
    "        self.state_memory[index]     = state\n",
    "        self.action_memory[index]    = action\n",
    "        self.reward_memory[index]    = reward\n",
    "        self.new_state_memory[index] = new_state\n",
    "        self.terminal_memory[index]  = done # problematic !!!\n",
    "\n",
    "        self.mem_cntr += 1\n",
    "\n",
    "    def sample_buffer(self, batch_size):\n",
    "        max_mem = min(self.mem_cntr, self.mem_size)\n",
    "\n",
    "        batch = np.random.choice(max_mem, batch_size, replace=False) # replace = False -> in a single batch, no element gets sampled more than once. \n",
    "\n",
    "        states     = self.state_memory[batch]\n",
    "        actions    = self.action_memory[batch]\n",
    "        rewards    = self.reward_memory[batch]\n",
    "        new_states = self.new_state_memory[batch]\n",
    "        dones      = self.terminal_memory[batch]\n",
    "\n",
    "        return states, actions, rewards, new_states, dones\n",
    "\n",
    "\n",
    "\n",
    "# =============================== CRITIC NETWORK ===============================\n",
    "class CriticNetwork(keras.Model):\n",
    "    def __init__(\n",
    "            self,\n",
    "            name=\"critic\", # model name (required by tf.keras.Model)\n",
    "            fc1_dims=512,\n",
    "            fc2_dims=512,\n",
    "            chkpt_dir='tmp/ddpg/'\n",
    "    ):\n",
    "        super(CriticNetwork, self).__init__()\n",
    "\n",
    "        self.model_name = name # do not use 'self.model'; it is a reserved variable name in tf\n",
    "        self.checkpoint_dir  = chkpt_dir\n",
    "        self.checkpoint_file = os.path.join(self.checkpoint_dir, self.model_name, '_ddpg.h5') \n",
    "        # extensions for saving keras models: legacy '.h5' -> TF 1.X, '.tf' -> TF 2.X\n",
    "\n",
    "        self.fc1_dims = fc1_dims\n",
    "        self.fc2_dims = fc2_dims\n",
    "\n",
    "        # define network layers \n",
    "        self.fc1 = Dense(self.fc1_dims, activation='relu')\n",
    "        self.fc2 = Dense(self.fc2_dims, activation='relu')\n",
    "        self.q   = Dense(1, activation=None)\n",
    "\n",
    "    def call(self, state, action):\n",
    "        temp1 = self.fc1(tf.concat([state, action], axis=1)) # axis 0 -> batch dimension\n",
    "        # ######################## PROBLEM ########################\n",
    "        # according to the paper, actions were not included until the 2nd hidden layer of Q\n",
    "        temp2 = self.fc2(temp1)\n",
    "        q_value = self.q(temp2)\n",
    "\n",
    "        return q_value\n",
    "\n",
    "# ================================ ACTOR NETWORK ===============================\n",
    "class ActorNetwork(keras.Model):\n",
    "    def __init__(\n",
    "            self,\n",
    "            name=\"actor\", # model name (required by tf.keras.Model)\n",
    "            n_actions=2, # action shape (dimenisonality of action space)\n",
    "            fc1_dims=512,\n",
    "            fc2_dims=512,\n",
    "            chkpt_dir='tmp/ddpg/'\n",
    "    ):\n",
    "        super(ActorNetwork, self).__init__()\n",
    "\n",
    "        self.model_name = name # do not use 'self.model'; it is a reserved variable name in tf\n",
    "        self.checkpoint_dir  = chkpt_dir\n",
    "        self.checkpoint_file = os.path.join(self.checkpoint_dir, self.model_name, '_ddpg.h5') \n",
    "\n",
    "        self.n_actions = n_actions\n",
    "        self.fc1_dims = fc1_dims\n",
    "        self.fc2_dims = fc2_dims\n",
    "\n",
    "        # define network layers\n",
    "        self.fc1 = Dense(self.fc1_dims,  activation='relu')\n",
    "        self.fc2 = Dense(self.fc2_dims,  activation='relu')\n",
    "        self.mu  = Dense(self.n_actions, activation='tanh') # action is bounded by +/- 1\n",
    "\n",
    "    def call(self, state):\n",
    "        temp1  = self.fc1(state)\n",
    "        temp2  = self.fc2(temp1)\n",
    "        action = self.mu(temp2)\n",
    "\n",
    "        return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"actor_network_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_78 (Dense)            multiple                  40        \n",
      "                                                                 \n",
      " dense_79 (Dense)            multiple                  110       \n",
      "                                                                 \n",
      " dense_80 (Dense)            multiple                  33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 183 (732.00 Byte)\n",
      "Trainable params: 183 (732.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "action: tf.Tensor(\n",
      "[[-0.13529369 -0.0278967   0.16720283]\n",
      " [-0.14543913 -0.08192513  0.1533877 ]\n",
      " [-0.22853766 -0.07132147  0.26780415]\n",
      " [-0.3539786  -0.15822871  0.39385724]\n",
      " [-0.3206752  -0.14606568  0.37063336]\n",
      " [-0.19451684 -0.0793639   0.2327903 ]\n",
      " [-0.25600296 -0.11198691  0.28655782]\n",
      " [-0.23539251 -0.08376358  0.27984625]\n",
      " [-0.13003598 -0.06071493  0.14174528]\n",
      " [-0.19105305 -0.08738813  0.21130867]], shape=(10, 3), dtype=float32)\n",
      "value: tf.Tensor(\n",
      "[[0.05679315]\n",
      " [0.20812887]\n",
      " [0.05555741]\n",
      " [0.16287515]\n",
      " [0.17583714]\n",
      " [0.1071803 ]\n",
      " [0.11366126]\n",
      " [0.08982027]\n",
      " [0.13343252]\n",
      " [0.14906041]], shape=(10, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "actor = ActorNetwork(n_actions=3, fc1_dims=10, fc2_dims=10)\n",
    "critic = CriticNetwork(fc1_dims=10, fc2_dims=10)\n",
    "state = np.random.rand(10, 3).astype(np.float32)\n",
    "action = actor(state)\n",
    "print(actor.summary())\n",
    "print(\"action:\", action)\n",
    "value = critic(state, action)\n",
    "print(\"value:\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=uint8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=uint8, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forcefully overwrite one value to 1\n",
    "value_ = np.arange(10); print(value_)\n",
    "value_tensor = tf.convert_to_tensor(value_, dtype=np.uint8); print(value_tensor)\n",
    "tf.squeeze(value_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# tf.GradientTape()\n",
    "x = tf.Variable(1.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x**3 + 2*x**2 - x + 1\n",
    "dy_dx = tape.gradient(y, x)\n",
    "print(dy_dx)\n",
    "# dy_dx = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: 4\n",
      "trainable_weights: 2\n",
      "non_trainable_weights: 2\n"
     ]
    }
   ],
   "source": [
    "# trainable and non-trainable weights\n",
    "\n",
    "layer = tf.keras.layers.BatchNormalization()\n",
    "layer.build((None, 4))  # Create the weights\n",
    "\n",
    "print(\"weights:\", len(layer.weights))\n",
    "print(\"trainable_weights:\", len(layer.trainable_weights))\n",
    "print(\"non_trainable_weights:\", len(layer.non_trainable_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
